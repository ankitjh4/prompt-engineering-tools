{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain notes- Prompt Design and prompt templating  \n",
    "1. **Prompt** is the input to a language model. It is a string of text that is used to generate a response from the language model. Example of a prompt would be \"what is the capital of India?\"\n",
    "2. **Prompt Template**- This is a template of a prompt that can take some user inputs and then generate a prompt from that. In a prompt we often see that there are some variables that can change from one prompt to another depending on the user input. This is like using the print command in Python for something as silly as when you were taught to take user name and you had to output a hello, user maessage from the user name. But this prompt template is a little more complex than that. Let's explore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"], \n",
    "    template=\"Tell me a {adjective} joke about {content}.\" # As you can see that the syntax looks exactly like the print command\n",
    ")\n",
    "\n",
    "'''\n",
    "By default prompt templates uses the f-string formatter that is otherwise used by python but there was \n",
    "another PR to integrate jinja formatting. We can change that using the prompt_template attribute\n",
    "'''\n",
    "\n",
    "multiple_input_prompt.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain happens to have some default prompt templates that you can use or you can also create your very own **custom prompt templates**. A custom prompt template would be necessary if yu have your own formatter / parser and you want to create a custom prompt engine from scratch based on inputs that you might receive from let's say an API. The code for this looks something like this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your date of birth in dd/mm/yyyy format16/07/1998\n",
      "\n",
      "        I want you to act as an astrologer for a prank. The date format we are going to use is dd/mm/yyyy\n",
      "        I was born on 16/07/1998 and today is 19/03/2023\n",
      "        You are going to maake several vague but true sounding predictions about my finances\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import BasePromptTemplate\n",
    "import re \n",
    "from datetime import datetime\n",
    "\n",
    "class ExamplePromptTemplate(BasePromptTemplate):\n",
    "    def get_user_birth_date(self):\n",
    "        user_input = input(\"Enter your date of birth in dd/mm/yyyy format\")\n",
    "\n",
    "        assert re.search(r'[0-9]{2}/[0-9]{2}/[0-9]{4}',user_input) != None\n",
    "        return user_input\n",
    "\n",
    "    def get_today_date(self):\n",
    "        return str(datetime.today().strftime('%d/%m/%Y'))\n",
    "    def format(self, **kwargs)-> str:\n",
    "        '''\n",
    "        Let's also assume that the user is going to give an input about what predictions they want as a function parameter\n",
    "        '''\n",
    "        # get the user DoB\n",
    "        birth_date = self.get_user_birth_date()\n",
    "        today_date = self.get_today_date()\n",
    "        prediction = kwargs['prediction']\n",
    "        \n",
    "        # Make sure to put f before string so that it is clear that it is a format string \n",
    "        prompt = f\"\"\"\n",
    "        I want you to act as an astrologer for a prank. The date format we are going to use is dd/mm/yyyy\n",
    "        I was born on {birth_date} and today is {today_date}\n",
    "        You are going to maake several vague but true sounding predictions about my {prediction}\n",
    "        \"\"\"\n",
    "        return prompt \n",
    "    def _prompt_type(self):  \n",
    "        '''\n",
    "        Required function\n",
    "        '''\n",
    "        return \"example-astrologer\"\n",
    "\n",
    "astrologer = ExamplePromptTemplate(input_variables=['prediction'])\n",
    "prompt = astrologer.format(prediction='finances')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain has something called a LangchainHub which is like hugging faces. It is a collection of artefacts that are useful for working with Langchain like \n",
    "1. prompts \n",
    "2. Chains \n",
    "3. Agents (we will learn what each of them are later during the course)\n",
    "\n",
    "We can also save the prompts that are in memory in multiple different formats uploaded to the langchainhub. \n",
    "A prompt can be locally saved in the following formats \n",
    "1. json '\n",
    "2. yaml\n",
    "3. Python - To get a properly formatted Python file, you should upload a Python file that exposes a PROMPT variable. This is the variable that will be loaded. This variable should be an instance of a subclass of BasePromptTemplate in LangChain.\n",
    "\n",
    "Additionally, you need to attach a README file to the prompt so as to have some usage guidelines fro the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.prompts.prompt.PromptTemplate'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "\n",
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"], \n",
    "    template=\"Tell me a {adjective} joke about {content}.\" # As you can see that the syntax looks exactly like the print command\n",
    ")\n",
    "\n",
    "multiple_input_prompt.save(\"prompt.json\")\n",
    "\n",
    "\n",
    "prompt = load_prompt(\"prompt.json\")\n",
    "print(type(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "multiple_input_prompt.save(\"multiple_input_prompt.json\")\n",
    "\n",
    "# This is how the prompt is going to be saved in memory \n",
    "'''\n",
    "{\n",
    "    \"input_variables\": [\n",
    "        \"adjective\",\n",
    "        \"content\"\n",
    "    ],\n",
    "    \"template\": \"Tell me a {adjective} joke about {content}.\",\n",
    "    \"template_format\": \"f-string\"\n",
    "}\n",
    "'''\n",
    "\n",
    "multiple_input_prompt.save(\"multiple_input_prompt.yaml\")\n",
    "# This is how this file is going to look like. Of course it would also store the template which is not the case of custom prompts \n",
    "'''\n",
    "input_variables:\n",
    "- adjective\n",
    "- content\n",
    "template: Tell me a {adjective} joke about {content}.\n",
    "template_format: f-string\n",
    "'''\n",
    "\n",
    "print(\"\") # For Jupyter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3- Few shot example prompts**- When you give the language model a few examples that showcase the kind of input output combination that is expected from it, those prompts are called few shot example prompts\n",
    "\n",
    "We can create a prompt template using a few shot example template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "examples = [\n",
    "  {\n",
    "    \"question\": \"Who lived longer, Muhammad Ali or Alan Turing?\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: How old was Muhammad Ali when he died?\n",
    "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
    "Follow up: How old was Alan Turing when he died?\n",
    "Intermediate answer: Alan Turing was 41 years old when he died.\n",
    "So the final answer is: Muhammad Ali\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"When was the founder of craigslist born?\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the founder of craigslist?\n",
    "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
    "Follow up: When was Craig Newmark born?\n",
    "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
    "So the final answer is: December 6, 1952\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Who was the maternal grandfather of George Washington?\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the mother of George Washington?\n",
    "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
    "Follow up: Who was the father of Mary Ball Washington?\n",
    "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
    "So the final answer is: Joseph Ball\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Are both the directors of Jaws and Casino Royale from the same country?\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who is the director of Jaws?\n",
    "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
    "Follow up: Where is Steven Spielberg from?\n",
    "Intermediate Answer: The United States.\n",
    "Follow up: Who is the director of Casino Royale?\n",
    "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
    "Follow up: Where is Martin Campbell from?\n",
    "Intermediate Answer: New Zealand.\n",
    "So the final answer is: No\n",
    "\"\"\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we see that our prompts follow the same key value pair pattern, we must at all costs put the prompts in a string format templayte using a prompttemplate object. The way to do this is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"Question: {question}\\n{answer}\")\n",
    "\n",
    "print(example_prompt.format(**examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit of creating one unified prompt template as such is that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n",
      "\n",
      "Question: When was the founder of craigslist born?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the founder of craigslist?\n",
      "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
      "Follow up: When was Craig Newmark born?\n",
      "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
      "So the final answer is: December 6, 1952\n",
      "\n",
      "\n",
      "Question: Who was the maternal grandfather of George Washington?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n",
      "\n",
      "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who is the director of Jaws?\n",
      "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
      "Follow up: Where is Steven Spielberg from?\n",
      "Intermediate Answer: The United States.\n",
      "Follow up: Who is the director of Casino Royale?\n",
      "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
      "Follow up: Where is Martin Campbell from?\n",
      "Intermediate Answer: New Zealand.\n",
      "So the final answer is: No\n",
      "\n",
      "\n",
      "Question: Who was the father of Mary Ball Washington?\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples, \n",
    "    example_prompt=example_prompt, \n",
    "    suffix=\"Question: {input}\", \n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "print(prompt.format(input=\"Who was the father of Mary Ball Washington?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n",
      "Examples most similar to the input: Who was the father of Mary Ball Washington?\n",
      "\n",
      "\n",
      "question: Who was the maternal grandfather of George Washington?\n",
      "answer: \n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # This is the list of examples available to select from.\n",
    "    examples,\n",
    "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OpenAIEmbeddings(openai_api_key=api),\n",
    "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    Chroma,\n",
    "    # This is the number of examples to produce.\n",
    "    k=1\n",
    ")\n",
    "\n",
    "# Select the most similar example to the input.\n",
    "question = \"Who was the father of Mary Ball Washington?\"\n",
    "selected_examples = example_selector.select_examples({\"question\": question})\n",
    "print(f\"Examples most similar to the input: {question}\")\n",
    "for example in selected_examples:\n",
    "    print(\"\\n\")\n",
    "    for k, v in example.items():\n",
    "        print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
